# LLM-backed Discord Chatbot

A multi-head Discord chatbot using discord.py and LiteLLM. Multiple LLM agents are supported
via webhooks, and agents will respond to conversation naturally without the need to explicitly
mention or reply to them.

## Prerequisites

- Python 3.12 or higher
- A Discord bot token
- An API key for your chosen LLM provider (e.g., OpenAI)
- A PostgreSQL database

## Installation

1. Clone this repository:
   ```
   git clone https://github.com/yourusername/llm-discord-bot.git
   cd llm-discord-bot
   ```

2. Create a virtual environment and activate it:
   ```
   python -m venv venv
   source venv/bin/activate
   ```

3. Install the required dependencies:
   ```
   pip install -r requirements.txt
   ```

## Configuration

1. Copy the `config-example.yml` file to a new file named `config.yml`:
   ```
   cp config-example.yml config.yml
   ```

2. Open the `config.yml` file and update the values:
    - Replace `your_discord_bot_token_here` with your actual Discord bot token.
    - Replace `your_discord_client_id_here` with your actual Discord client ID.
    - Set the `database_url` to the connection string for your database.

3. The `config-example.yml` file contains explanations for all available settings. Refer to it for more information on
   configuring your bot.

Note: The `config.yml` file is gitignored to prevent accidental commits of sensitive information.

## Database Migrations

This project uses Alembic for database migrations. Here's how to work with migrations:

1. To create a new migration:
   ```
   alembic revision --autogenerate -m "Description of changes"
   ```

2. To apply all pending migrations:
   ```
   alembic upgrade head
   ```

3. To revert the last migration:
   ```
   alembic downgrade -1
   ```

4. To view migration history:
   ```
   alembic history
   ```

Note: Always review autogenerated migrations before applying them to ensure they accurately reflect your intended
changes.

## Running the Bot

To start the bot, run:

```
python src/main.py
```

The bot will connect to Discord and print a message when ready.

## Usage

Mention an agent with `@agent` (literal, do not use the suggestions!) to summon it. You can continue
conversation by replying to one of its messages, or if you configure a simulator, you can
just post; the LLMs will reply naturally.

### Configuration

The bot is configured via Discord slash commands. Here's an in-depth guide to each slash command:

#### /llm list
**Description:** Lists all available LLMs for the current guild.
**Arguments:** None
**Usage:** This command displays a list of all configured LLMs in the current Discord server, showing their names, whether they're enabled or disabled, and the model they're using.

#### /llm create
**Description:** Registers a new LLM for use in the current guild.
**Arguments:**
- `name`: Name of the new LLM (required)
- `api_base`: API base URL path (required)
- `llm_name`: Name of the model (required)
- `api_key`: API secret key (required, don't share this!)
- `max_tokens`: Maximum number of tokens per response (required)
- `context_length`: Context length in tokens (required)
- `message_limit`: Number of messages to put in LLM's context (required)
- `system_prompt`: System prompt to be displayed at start of context (optional)
- `temperature`: Sampling temperature, default is 1.0 (optional)
- `top_p`: Sampling top_p value (optional)
- `top_k`: Sampling top_k value, not supported by all APIs (optional)
- `frequency_penalty`: Sampling frequency penalty (optional)
- `presence_penalty`: Sampling presence penalty (optional)
- `repetition_penalty`: Sampling repetition penalty, not supported by all APIs (optional)
- `min_p`: Sampling min_p value, not supported by all APIs (optional)
- `top_a`: Sampling top_a value, not supported by all APIs (optional)
- `instruct_tuned`: Whether or not the LLM has been instruct tuned, default is true (optional)
- `message_formatter`: Formatter to use for this LLM (optional)
- `enabled`: Whether or not the llm should respond to messages, default is true (optional)

**Usage:** Use this command to add a new LLM to your Discord server. You'll need to provide the necessary API details and configuration parameters.

#### /llm modify
**Description:** Modifies an existing LLM in the current guild.
**Arguments:** Same as `/llm create`, but with:
- `name`: Name of the LLM to modify (required)
- `new_name`: New name for the LLM (optional)

**Usage:** Use this command to update the configuration of an existing LLM. You only need to provide the parameters you want to change.

#### /llm delete
**Description:** Deletes an existing LLM from the current guild.
**Arguments:**
- `name`: Name of the LLM to delete (required)

**Usage:** Use this command to remove an LLM from your Discord server.

#### /llm copy
**Description:** Creates a deep copy of an existing LLM with a new name.
**Arguments:**
- `source_name`: Name of the existing LLM (required)
- `new_name`: Name for the new copy (required)

**Usage:** Use this command to duplicate an existing LLM configuration under a new name.

#### /llm set_avatar
**Description:** Sets an avatar for an LLM.
**Arguments:**
- `name`: Name of the LLM (required)
- `image_url`: URL of the image to use as avatar (required)

**Usage:** Use this command to set or update the avatar image for an LLM.

#### /llm print
**Description:** Prints the configuration of an LLM.
**Arguments:**
- `name`: Name of the LLM (required)

**Usage:** Use this command to view the detailed configuration of a specific LLM.

#### /llm sync
**Description:** Syncs the bot commands with the current guild.
**Arguments:** None

**Usage:** Use this command to update the available slash commands in your Discord server after making changes to the bot.

#### /llm help
**Description:** Provides help information about bot commands and LLM interaction.
**Arguments:** None

**Usage:** Use this command to get an overview of available commands and how to interact with LLMs.

#### /llm set_simulator
**Description:** Sets the LLM for simulating responses.
**Arguments:**
- `name`: Name of the LLM to use as simulator (required)

**Usage:** Use this command to designate an LLM as the simulator for natural conversation flow.

#### /llm set_simulator_channel
**Description:** Sets the channel for viewing raw simulator responses.
**Arguments:**
- `channel`: The text channel to use for simulator responses (required)

**Usage:** Use this command to specify a channel where the raw simulator responses will be sent.

#### Simulator

To enable natural replies, you must configure a base model simulator. At present the best choice for this task is
Llama 3.1 405b. Here's an example of how you can do that with 405b on Openrouter:

First, create the base model LLM. It is named `simulator` here by convention.

```
/llm create name:simulator api_base:https://openrouter.ai/api/v1 llm_name:meta-llama/llama-3.1-405b api_key:YOUR_API_KEY_HERE max_tokens:256 context_length:131072 message_limit:100 enabled:False instruct_tuned:False
```

Next, set the Discord server's simulator model:

```
/llm set_simulator name:simulator
```

Your simulator has been configured. LLMs are now able to respond without an explicit mention or reply.
You can also, optionally, display the simulated conversations in a
channel of your choice. Sometimes it's interesting to see what the base model thinks you'll say next.

```
/llm set_simulator_channel channel:#example
```

Please note that other providers may not work or may result in bugs. Please report any errors that occur!

## Development

- To run tests: `pytest tests/`

## Note

Ensure that your Discord bot has the necessary permissions in your server, including the ability to read messages and
send responses.
