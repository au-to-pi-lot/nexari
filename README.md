# LLM-backed Discord Chatbot

A multi-head Discord chatbot using discord.py and LiteLLM. Multiple LLM agents are supported
via webhooks, and agents will respond to conversation naturally without the need to explicitly
mention or reply to them.

## Prerequisites

- Python 3.12 or higher
- A Discord bot token
- An API key for your chosen LLM provider (e.g., OpenAI)
- A PostgreSQL database

## Installation

1. Clone this repository:
   ```
   git clone https://github.com/yourusername/llm-discord-bot.git
   cd llm-discord-bot
   ```

2. Create a virtual environment and activate it:
   ```
   python -m venv venv
   source venv/bin/activate
   ```

3. Install the required dependencies:
   ```
   pip install -r requirements.txt
   ```

## Configuration

1. Copy the `config-example.yml` file to a new file named `config.yml`:
   ```
   cp config-example.yml config.yml
   ```

2. Open the `config.yml` file and update the values:
    - Replace `your_discord_bot_token_here` with your actual Discord bot token.
    - Replace `your_discord_client_id_here` with your actual Discord client ID.
    - Set the `database_url` to the connection string for your database.

3. The `config-example.yml` file contains explanations for all available settings. Refer to it for more information on
   configuring your bot.

Note: The `config.yml` file is gitignored to prevent accidental commits of sensitive information.

## Database Migrations

This project uses Alembic for database migrations. Here's how to work with migrations:

1. To create a new migration:
   ```
   alembic revision --autogenerate -m "Description of changes"
   ```

2. To apply all pending migrations:
   ```
   alembic upgrade head
   ```

3. To revert the last migration:
   ```
   alembic downgrade -1
   ```

4. To view migration history:
   ```
   alembic history
   ```

Note: Always review autogenerated migrations before applying them to ensure they accurately reflect your intended
changes.

## Running the Bot

To start the bot, run:

```
python src/main.py
```

The bot will connect to Discord and print a message when ready.

## Usage

Mention an agent with `@agent` (literal, do not use the suggestions!) to summon it. You can continue
conversation by replying to one of its messages, or if you configure a simulator, you can
just post; the LLMs will reply naturally.

### Configuration

The bot is configured via Discord slash commands.

TODO: Write an in-depth guide to each slash command, describing what it does and explaining each of its arguments.


#### Simulator

To enable natural replies, you must configure a base model simulator. At present the best choice for this task is
Llama 3.1 405b. Here's an example of how you can do that with 405b on Openrouter:

First, create the base model LLM. It is named `simulator` here by convention.

```
/llm create name:simulator api_base:https://openrouter.ai/api/v1 llm_name:meta-llama/llama-3.1-405b api_key:YOUR_API_KEY_HERE max_tokens:256 context_length:131072 message_limit:100 enabled:False instruct_tuned:False
```

Next, set the Discord server's simulator model:

```
/llm set_simulator name:simulator
```

Your simulator has been configured. LLMs are now able to respond without an explicit mention or reply.
You can also, optionally, display the simulated conversations in a
channel of your choice. Sometimes it's interesting to see what the base model thinks you'll say next.

```
/llm set_simulator_channel channel:#example
```

Please note that other providers may not work or may result in bugs. Please report any errors that occur!

## Development

- To run tests: `pytest tests/`

## Note

Ensure that your Discord bot has the necessary permissions in your server, including the ability to read messages and
send responses.
